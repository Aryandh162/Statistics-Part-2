{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Part 2 Assignment"
      ],
      "metadata": {
        "id": "Jq8dA0gFsGvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics?\n"
      ],
      "metadata": {
        "id": "CgIF5U2_sViT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Hypothesis testing is a statistical method used to make decisions or draw conclusions about a population based on sample data. It involves formulating two competing hypotheses: the null hypothesis and the alternative hypothesis. We then collect and analyze data to determine which hypothesis is better supported by the evidence."
      ],
      "metadata": {
        "id": "KRqxP_wPw1wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n"
      ],
      "metadata": {
        "id": "TSbCB3TFtdox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Null Hypothesis\n",
        "\n",
        "Definition: The null hypothesis is a statement that assumes there is no significant difference, effect, or relationship between two or more variables. It represents the status quo or the default assumption. It's often a statement of \"no effect\" or \"no difference.\"\n",
        "\n",
        " Alternative Hypothesis\n",
        "\n",
        "Definition: The alternative hypothesis is a statement that contradicts the null hypothesis. It proposes that there is a significant difference, effect, or relationship between variables."
      ],
      "metadata": {
        "id": "rrC8qQyCw3m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the significance level in hypothesis testing, and why is it important?\n"
      ],
      "metadata": {
        "id": "HEmfOMJOtfnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> In hypothesis testing, the significance level is the criteria or threshold value based on which one can reject the null hypothesis or fail to reject the null hypothesis. It is also called the alpha level. The significance level defines the strength of evidence in probabilistic terms. It is the fixed probability of wrong elimination of null hypothesis when in fact, it is true. The significance level is reported as the P-value, which is the probability of seeing data that are as extreme or more extreme than those that were observed."
      ],
      "metadata": {
        "id": "_HbtJnCAxUbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does a P-value represent in hypothesis testing?\n"
      ],
      "metadata": {
        "id": "XVPAdpZDth1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The p-value, or probability value, is a statistical measure used in hypothesis testing to assess the strength of evidence against a null hypothesis. It represents the probability of obtaining results as extreme as, or more extreme than, the observed results under the assumption that the null hypothesis is true.\n"
      ],
      "metadata": {
        "id": "45EzTBn9xeuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you interpret the P-value in hypothesis testing?"
      ],
      "metadata": {
        "id": "2QeoERgutjf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The p-value, or probability value, is a statistical measure used in hypothesis testing to assess the strength of evidence against a null hypothesis. It represents the probability of obtaining results as extreme as, or more extreme than, the observed results under the assumption that the null hypothesis is true."
      ],
      "metadata": {
        "id": "70dm2hyqxg9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are Type 1 and Type 2 errors in hypothesis testing?"
      ],
      "metadata": {
        "id": "I7Out-2YtmG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Type I Error (False Positive)\n",
        "\n",
        "A Type I error occurs when the null hypothesis (H0) is rejected when it is actually true. This means concluding that there is an effect or difference when there isn't one. The probability of making a Type I error is denoted by alpha (α), which is the significance level set by the researcher. For example, if α is set to 0.05, there is a 5% chance of making a Type I error\n",
        "\n",
        "\n",
        "Type II Error (False Negative)\n",
        "\n",
        "A Type II error occurs when the null hypothesis is not rejected when it is actually false. This means failing to detect an effect or difference when one actually exists. The probability of making a Type II error is denoted by beta (β). The power of a test, which is 1 - β, indicates the likelihood of correctly rejecting a false null hypothesis"
      ],
      "metadata": {
        "id": "FP18amDXxqKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n"
      ],
      "metadata": {
        "id": "fTw15NJ-toF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> One-Tailed Test\n",
        "\n",
        "A one-tailed test is used when the alternative hypothesis specifies a direction. It tests whether a parameter is either greater than or less than a certain value, but not both. The critical region, where the null hypothesis is rejected, lies entirely on one side of the sampling distribution. For example, if we want to test whether a machine produces more than 1% defective products, we would use a one-tailed test\n",
        "\n",
        "Two-Tailed Test\n",
        "\n",
        "A two-tailed test is used when the alternative hypothesis does not specify a direction. It tests whether a parameter is either greater than or less than a certain range of values. The critical regions lie on both sides of the sampling distribution. For example, if we want to test whether a new bill affects the loans of farmers, we would use a two-tailed test\n"
      ],
      "metadata": {
        "id": "BKGrmXUZxwPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the Z-test, and when is it used in hypothesis testing?\n"
      ],
      "metadata": {
        "id": "qHmd4pZGtp71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> After learning about inferential statistics we now move on to a more specific technique used for making decisions based on sample data – the Z-test. Studying entire populations can be time-consuming, costly and sometimes impossible. so instead you take a sample from that population.\n",
        "\n",
        "This is where the Z-test becomes important. It helps us make inferences about the entire population based on the sample data."
      ],
      "metadata": {
        "id": "K4h4qv_v4c2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n"
      ],
      "metadata": {
        "id": "T7g9obYGtrhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> A Z-test is a type of hypothesis test that compares the sample’s average to the population’s average and calculates the Z-score and tells us how much the sample average is different from the population average by looking at how much the data normally varies."
      ],
      "metadata": {
        "id": "gYhg0wEO4j6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?"
      ],
      "metadata": {
        "id": "i8Fkc-pYttJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Normal Distribution is used for larger sample sizes and when the population standard deviation is known, while t-Distribution is used for smaller sample sizes and when the population standard deviation is unknown."
      ],
      "metadata": {
        "id": "UcOo1dtG4pAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is the difference between a Z-test and a T-test?"
      ],
      "metadata": {
        "id": "L2j3gQPQuF_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Z-test refers to a univariate statistical analysis used to test the hypothesis that proportions from two independent samples differ greatly. It determines to what extent a data point is away from its mean of the data set, in standard deviation.The researcher adopts z-test, when the population variance is known, in essence, when there is a large sample size, sample variance is deemed to be approximately equal to the population variance. In this way, it is assumed to be known, despite the fact that only sample data is available and so normal test can be applied.\n",
        "\n",
        "A t-test is a hypothesis test used by the researcher to compare population means for a variable, classified into two categories depending on the less-than interval variable. More precisely, a t-test is used to examine how the means taken from two independent samples differ.\n",
        "\n",
        "T-test follows t-distribution, which is appropriate when the sample size is small, and the population standard deviation is not known. The shape of a t-distribution is highly affected by the degree of freedom. The degree of freedom implies the number of independent observations in a given set of observations."
      ],
      "metadata": {
        "id": "55QdayrX41G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the T-test, and how is it used in hypothesis testing?"
      ],
      "metadata": {
        "id": "xptfwWYjuIMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> T-Test is a method used in statistics to determine if there is a significant difference between the means of two groups and how they are related. In T-Test statistics, the sample data is a subset of the two groups that we use to draw conclusions about the groups as a whole."
      ],
      "metadata": {
        "id": "4tyjVMKZ5DjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n"
      ],
      "metadata": {
        "id": "qzqByKrCuKJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> T-Test\n",
        "\n",
        "A t-test is used to determine if there is a significant difference between the means of two groups or between a sample mean and a known value. It is particularly useful when dealing with small sample sizes (n < 30) or when the population variance is unknown\n",
        "1\n",
        "2\n",
        ". The t-test relies on the t-distribution, which has heavier tails than the normal distribution to account for the additional variability and uncertainty.\n",
        "\n",
        "Types of T-Tests\n",
        "\n",
        "One-Sample T-Test: Compares the mean of a single sample to a known value or population mean.\n",
        "Independent Two-Sample T-Test: Compares the means of two independent groups.\n",
        "Paired T-Test: Compares means from the same group at different times or under different conditions\n",
        "\n",
        "Z-Test\n",
        "\n",
        "A Z-test is used to determine if there is a significant difference between the sample mean and the population mean or between the means of two groups when the population variance is known and the sample size is large (n ≥ 30)\n"
      ],
      "metadata": {
        "id": "8s6xD-hc5M0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is a confidence interval, and how is it used to interpret statistical results?"
      ],
      "metadata": {
        "id": "Xe1xEx2uuMF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Confidence intervals are a fundamental concept in general statistics and are widely used to quantify uncertainty in an estimate. They have a wide range of applications, from evaluating the effectiveness of a drug, predicting election results, or analyzing sales data."
      ],
      "metadata": {
        "id": "4KjBf8k05Vrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the margin of error, and how does it affect the confidence interval?\n"
      ],
      "metadata": {
        "id": "03z9WTs8uObI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> In statistics, both margin of error and confidence interval are crucial concepts used to estimate the value of a population parameter with a certain level of confidence. However, they serve different purposes and are calculated differently.\n",
        "\n",
        "Confidence Interval\n",
        "\n",
        "A confidence interval is a range of values, derived from a sample, that is likely to contain the value of an unknown population parameter."
      ],
      "metadata": {
        "id": "RWE5E4aH5cqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How is Bayes' Theorem used in statistics, and what is its significance?"
      ],
      "metadata": {
        "id": "OouOQgO5uQJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Bayes' Theorem Explained in Detail\n",
        "\n",
        "Bayes' Theorem, named after the English statistician Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update the probability of a hypothesis based on new evidence or information. The theorem is widely used in various fields, including medicine, engineering, finance, and machine learning."
      ],
      "metadata": {
        "id": "yaJle8DS5inQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is the Chi-square distribution, and when is it used?"
      ],
      "metadata": {
        "id": "O-iyjbb5uSBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Chi-square (Χ2) distributions are a family of continuous probability distributions. They’re widely used in hypothesis tests, including the chi-square goodness of fit test and the chi-square test of independence.\n",
        "\n",
        "The shape of a chi-square distribution is determined by the parameter k, which represents the degrees of freedom.\n",
        "\n",
        "Very few real-world observations follow a chi-square distribution. The main purpose of chi-square distributions is hypothesis testing, not describing real-world distributions."
      ],
      "metadata": {
        "id": "rQxhDsEl5tYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the Chi-square goodness of fit test, and how is it applied?"
      ],
      "metadata": {
        "id": "eBLUA4BRuToh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> A Chi-Square goodness of fit test is used to determine whether or not a categorical variable follows a hypothesized distribution.\n",
        "\n",
        "This tutorial explains the following:\n",
        "\n",
        "The motivation for performing a Chi-Square goodness of fit test.\n",
        "The formula to perform a Chi-Square goodness of fit test.\n",
        "An example of how to perform a Chi-Square goodness of fit test."
      ],
      "metadata": {
        "id": "8npLGNFa5u04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is the F-distribution, and when is it used in hypothesis testing?"
      ],
      "metadata": {
        "id": "3kFlE39QuVSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> F test is a statistical test that is used in hypothesis testing to check whether the variances of two populations or two samples are equal or not. In an f test, the data follows an f distribution. This test uses the f statistic to compare two variances by dividing them."
      ],
      "metadata": {
        "id": "--TA1bO05_--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an ANOVA test, and what are its assumptions?\n"
      ],
      "metadata": {
        "id": "qESGFmopuW64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> ANOVA  is a statistical test used to determine if there are significant differences between the means of three or more independent groups. Before conducting an ANOVA test, it is crucial to ensure that certain assumptions are met to ensure the validity and reliability of the results."
      ],
      "metadata": {
        "id": "2gDUQT8q6BQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What are the different types of ANOVA tests?"
      ],
      "metadata": {
        "id": "yCXRN3g7uYcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups. There are two main types of ANOVA tests:\n",
        "1. One-Way ANOVA\n",
        "2. Two-Way ANOVA"
      ],
      "metadata": {
        "id": "WRjRbH5I6WZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the F-test, and how does it relate to hypothesis testing?"
      ],
      "metadata": {
        "id": "jKAAQSE7uZ9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> F test is a statistical test that is used in hypothesis testing that determines whether the variances of two samples are equal or not. The article will provide detailed information on f test, f statistic, its calculation, critical value and how to use it to test hypotheses.\n",
        "\n"
      ],
      "metadata": {
        "id": "raFtzliu6Z-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "URiaszdN6jCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Write a Python program to generate a random variable and display its value\n"
      ],
      "metadata": {
        "id": "30Ik4sXV6oPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import random\n",
        "\n",
        "random_variable = random.randint(1, 10)\n",
        "\n",
        "print(\"The random variable is:\", random_variable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC60z_ce8VJc",
        "outputId": "5542641f-7b87-4b0f-f69a-2ed43817bd5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The random variable is: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)\n"
      ],
      "metadata": {
        "id": "oH_zIPTi6-el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "low = 1\n",
        "high = 7\n",
        "\n",
        "sample = np.random.uniform(low, high, size=10000).astype(int)\n",
        "\n",
        "values, counts = np.unique(sample, return_counts=True)\n",
        "pmf = counts / len(sample)\n",
        "\n",
        "plt.bar(values, pmf)\n",
        "plt.title('Discrete Uniform Distribution PMF')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zJbatFr38aPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution\n"
      ],
      "metadata": {
        "id": "NCtOYbyx7AH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "def bernoulli_pdf(x, p):\n",
        "\n",
        "    if x == 1:\n",
        "        return p\n",
        "    elif x == 0:\n",
        "        return 1 - p\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "WcErZA6n8a-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram\n"
      ],
      "metadata": {
        "id": "P1FzT3Qb7BoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "p = 0.5\n",
        "\n",
        "sample = np.random.binomial(n, p, size=10000)\n",
        "\n",
        "plt.hist(sample, bins=range(min(sample), max(sample) + 2), align='left', rwidth=0.8)\n",
        "plt.title('Binomial Distribution (n=10, p=0.5)')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(range(min(sample), max(sample) + 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PFq1Pv5K8bc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Poisson distribution and visualize it using Python\n"
      ],
      "metadata": {
        "id": "Q6-EzH-Y7DOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lambda_param = 5\n",
        "\n",
        "sample = np.random.poisson(lambda_param, size=10000)\n",
        "\n",
        "plt.hist(sample, bins=range(min(sample), max(sample) + 2), align='left', rwidth=0.8)\n",
        "plt.title('Poisson Distribution (λ = 5)')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(range(min(sample), max(sample) + 1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w8_1IcEM8cFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution\n"
      ],
      "metadata": {
        "id": "mZ7AyzGH7EvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "low = 1\n",
        "high = 7\n",
        "\n",
        "sample = np.random.uniform(low, high, size=10000).astype(int)\n",
        "\n",
        "values, counts = np.unique(sample, return_counts=True)\n",
        "cdf = np.cumsum(counts) / len(sample)\n",
        "\n",
        "plt.plot(values, cdf, marker='o')\n",
        "plt.title('Discrete Uniform Distribution CDF')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.xticks(values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A_I_DkGk8ckc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Generate a continuous uniform distribution using NumPy and visualize it\n"
      ],
      "metadata": {
        "id": "0_0LHZ787GLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "low = 0\n",
        "high = 1\n",
        "\n",
        "sample = np.random.uniform(low, high, size=10000)\n",
        "\n",
        "plt.hist(sample, bins=50, density=True)\n",
        "plt.title('Continuous Uniform Distribution')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NIwmTvBW8dDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Simulate data from a normal distribution and plot its histogram\n"
      ],
      "metadata": {
        "id": "Ulax-xLk7HfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "sample = np.random.normal(mean, std_dev, size=10000)\n",
        "\n",
        "plt.hist(sample, bins=50, density=True)\n",
        "plt.title('Normal Distribution')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yXeUOXa78ddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python function to calculate Z-scores from a dataset and plot them\n"
      ],
      "metadata": {
        "id": "Kz4q_gED7I-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_z_scores(data):\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data)\n",
        "    z_scores = (data - mean) / std_dev\n",
        "    return z_scores\n",
        "\n",
        "data = np.array([1, 2, 3, 4, 5])\n",
        "z_scores = calculate_z_scores(data)\n",
        "\n",
        "plt.scatter(data, z_scores)\n",
        "plt.title('Z-Scores vs. Data')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Z-Scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a5fyR_Do8d7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution."
      ],
      "metadata": {
        "id": "IG_2SDzm7Khp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_size = 100\n",
        "num_samples = 10000\n",
        "\n",
        "samples = np.random.normal(0, 1, size=(num_samples, sample_size))\n",
        "sample_means = np.mean(samples, axis=1)\n",
        "\n",
        "plt.hist(sample_means, bins=50, density=True)\n",
        "plt.title('Central Limit Theorem (CLT) for Non-Normal Distribution')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0zDe1RY8eT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem."
      ],
      "metadata": {
        "id": "Rdm9ITvm7LSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_size = 100\n",
        "num_samples = 10000\n",
        "\n",
        "samples = np.random.normal(0, 1, size=(num_samples, sample_size))\n",
        "sample_means = np.mean(samples, axis=1)\n",
        "\n",
        "plt.hist(sample_means, bins=50, density=True)\n",
        "plt.title('Central Limit Theorem (CLT) for Non-Normal Distribution')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LigAcVpo8evo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1).\n"
      ],
      "metadata": {
        "id": "4ohVW2g972nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "    mean = 0\n",
        "    std_dev = 1\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev)**2)\n",
        "    plt.plot(x, y)\n",
        "    plt.title('Standard Normal Distribution')\n",
        "    plt.xlabel('Values')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.show()\n",
        "\n",
        "plot_standard_normal_distribution()\n"
      ],
      "metadata": {
        "id": "HyWqJe0r8fJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Generate random variables and calculate their corresponding probabilities using the binomial distribution."
      ],
      "metadata": {
        "id": "8YpqjrRI75Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "p = 0.5\n",
        "\n",
        "sample = np.random.binomial(n, p, size=10000)\n",
        "\n",
        "values, counts = np.unique(sample, return_counts=True)\n",
        "probabilities = counts / len(sample)\n",
        "\n",
        "plt.bar(values, probabilities)\n",
        "plt.title('Binomial Distribution')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f7aIz43C8fkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution."
      ],
      "metadata": {
        "id": "6qkrRGRZ77KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_z_score(data_point, mean, std_dev):\n",
        "    z_score = (data_point - mean) / std_dev\n",
        "    return z_score\n",
        "\n",
        "data_point = 1.5\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "z_score = calculate_z_score(data_point, mean, std_dev)\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev)**2)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.axvline(x=data_point, color='red', linestyle='--')\n",
        "plt.title('Standard Normal Distribution')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tylk1jKN8gBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Implement hypothesis testing using Z-statistics for a sample dataset."
      ],
      "metadata": {
        "id": "k3G-Xjnl79W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "data = np.array([1, 2, 3, 4, 5])\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data)\n",
        "z_statistic = (mean - 3) / (std_dev / np.sqrt(len(data)))\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_statistic)))\n",
        "\n",
        "print(\"Z-statistic:\", z_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "eEFlaTl98gr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Create a confidence interval for a dataset using Python and interpret the result."
      ],
      "metadata": {
        "id": "kE97RHvE7_h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.array([1, 2, 3, 4, 5])\n",
        "confidence_level = 0.95\n",
        "degrees_freedom = len(data) - 1\n",
        "\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data, ddof=1)\n",
        "standard_error = std_dev / np.sqrt(degrees_freedom)\n",
        "confidence_interval = t.interval(confidence_level, degrees_freedom, loc=mean, scale=standard_error)\n",
        "\n",
        "print(\"Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "id": "BCUG_K_g8hH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean."
      ],
      "metadata": {
        "id": "_SEKuvPR8Bgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.random.normal(loc=5, scale=2, size=100)\n",
        "confidence_level = 0.95\n",
        "degrees_freedom = len(data) - 1\n",
        "\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data, ddof=1)\n",
        "standard_error = std_dev / np.sqrt(degrees_freedom)\n",
        "confidence_interval = t.interval(confidence_level, degrees_freedom, loc=mean, scale=standard_error)\n",
        "\n",
        "print(\"Confidence Interval:\", confidence_interval)"
      ],
      "metadata": {
        "id": "WEt5IdHw8hl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution."
      ],
      "metadata": {
        "id": "DPqnrOg28Dg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)`\n",
        "y = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev)**2)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('Normal Distribution PDF')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LfwSAE1l8iCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution."
      ],
      "metadata": {
        "id": "SuczOZKH8Fgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lambda_param = 5\n",
        "\n",
        "x = np.arange(0, 10)\n",
        "y = np.exp(-lambda_param) * (lambda_param ** x) / np.math.factorial(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('Poisson Distribution CDF')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_Wp20nU8ifG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Simulate a random variable using a continuous uniform distribution and calculate its expected value."
      ],
      "metadata": {
        "id": "PLH5NlpM8HoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "\n",
        "low = 0\n",
        "high = 1\n",
        "\n",
        "sample = np.random.uniform(low, high, size=10000)\n",
        "expected_value = np.mean(sample)\n",
        "\n",
        "print(\"Expected Value:\", expected_value)\n",
        "\n"
      ],
      "metadata": {
        "id": "WiLH6TjQ8i3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to compare the standard deviations of two datasets and visualize the difference."
      ],
      "metadata": {
        "id": "BPomi6w38Jri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot\n",
        "\n",
        "\n",
        "data1 = np.random.normal(loc=0, scale=1, size=1000)\n",
        "data2 = np.random.normal(loc=0, scale=2, size=1000)\n",
        "\n",
        "std_dev1 = np.std(data1)\n",
        "std_dev2 = np.std(data2)\n",
        "\n",
        "plt.hist(data1, bins=50, alpha=0.5, label='Dataset 1')\n",
        "plt.hist(data2, bins=50, alpha=0.5, label='Dataset 2')\n",
        "plt.title('Comparison of Standard Deviations')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5yehPWL58jM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution."
      ],
      "metadata": {
        "id": "oesiOTFP8MFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.normal(loc=0, scale=1, size=1000)\n",
        "\n",
        "data_range = np.max(data) - np.min(data)\n",
        "q1 = np.percentile(data, 25)\n",
        "q3 = np.percentile(data, 75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "print(\"Range:\", data_range)\n",
        "print(\"Interquartile Range (IQR):\", iqr)\n",
        "\n"
      ],
      "metadata": {
        "id": "bmZR5NGe8jnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Implement Z-score normalization on a dataset and visualize its transformation."
      ],
      "metadata": {
        "id": "U9OG48fL8PgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.array([1, 2, 3, 4, 5])\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data)\n",
        "normalized_data = (data - mean) / std_dev\n",
        "\n",
        "plt.scatter(data, normalized_data)\n",
        "plt.title('Z-score Normalization')\n",
        "plt.xlabel('Original Data')\n",
        "plt.ylabel('Normalized Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BYO-_0dU8kCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution."
      ],
      "metadata": {
        "id": "0creK2hy8Rki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above ques.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.normal(loc=0, scale=1, size=1000)\n",
        "\n",
        "skewness = np.mean((data - np.mean(data))**3) / (np.std(data)**3)\n",
        "kurtosis = np.mean((data - np.mean(data))**4) / (np.std(data)**4)\n",
        "\n",
        "print(\"Skewness:\", skewness)\n",
        "print(\"Kurtosis:\", kurtosis)\n"
      ],
      "metadata": {
        "id": "tYETWo3_8kkZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}